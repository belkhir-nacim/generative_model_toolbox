import argparse
import pickle

import lmdb
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from .dataset import CodeRow, ImageFileDataset
from .vqvae import VQVAE


def extract(lmdb_env, loader, model, device):
    index = 0

    with lmdb_env.begin(write=True) as txn:
        pbar = tqdm(loader)

        for x, _, filename in pbar:
            x = x.to(device)

            with torch.no_grad():
                _, _, _, id_t, id_b = model.encode(x)
            id_t = id_t.detach().cpu().numpy()
            id_b = id_b.detach().cpu().numpy()

            for file, top, bottom in zip(filename, id_t, id_b):
                row = CodeRow(top=top, bottom=bottom, filename=file)
                txn.put(str(index).encode('utf-8'), pickle.dumps(row))
                index += 1
                pbar.set_description(f'inserted: {index}')
        txn.put('length'.encode('utf-8'), str(index).encode('utf-8'))


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--size', type=int, default=256)
    parser.add_argument('--model_path', type=str)
    parser.add_argument('--name', type=str)
    parser.add_argument('path', type=str)

    args = parser.parse_args()

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    transform = transforms.Compose(
        [
            transforms.Resize(args.size),
            transforms.CenterCrop(args.size),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
        ]
    )

    dataset = ImageFileDataset(args.path, transform=transform)
    loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)

    model = VQVAE()
    model.load_state_dict(torch.load(args.model_path))
    model = model.to(device)
    model.eval()

    map_size = 100 * 1024 * 1024 * 1024
    env = lmdb.open(args.name, map_size=map_size)

    extract(env, loader, model, device)


if __name__ == '__main__':
    main()

